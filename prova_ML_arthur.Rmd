---
title: "Aprendizagem de maquina"
author: "Arthur Henrique Elias de Lima"
date: '2023-08-21'
output: html_document
---
1-Explique resumidamente o que é aprendizagem supervisionada e não-supervisionada. Cite um problema de aprendizagem supervisionada e um outro de aprendizagem não-supervisionada.


Supervisionada utiliza conjuntos de dados rotulados, sem a necessidade de uma pessoa externa para compreender o assunto.


Não supervisionada é quando não temos a resposta correta do conteudo, ou seja, temos a necessidade de pessoas externas para entendimento do assunto. 


2-Considere o conjunto de dados de Expectativa de vida versus PIB per Capita, disponível aqui. Considere a função gg, da seguinte forma:


com p \in \{1, 2, ..., 50\} p∈{1,2,...,50}. Utilizando o erro quadrático médio observado, sem fazer nenhuma estratégia de divisão dos dados, implemente um código em R para checar qual o melhor modelo.

```{r}
setwd("E:/Downloads/archive (7)")
load("E:/Downloads/archive (7)/dados_expectativa_renda.RData")
set.seed(2023)
library(rsample)
library(dplyr)
library(ggplot2)
library(tidymodels)
library(tibble)
library(purrr)
library(patchwork)
library(glmnet)
tidymodels::tidymodels_prefer()

```


```{r message=FALSE, warning=FALSE}
dados <- dados_expectativa_renda[,-1]

dados_splitted <- initial_split(dados)

cross_validation <- vfold_cv(training(dados_splitted), v = 50)

eqm <- NULL

for(i in 1:50){
  data_temp <- cross_validation$splits[[i]] %>% analysis()
  fit_temp <- lm(data_temp$LifeExpectancy~., data_temp)
  
  Validatiion_temp <- cross_validation$splits[[i]] %>% assessment()
  
  eqm[i] <-  apply((Validatiion_temp[,1] - predict(fit_temp, Validatiion_temp))^2, MARGIN = 2, mean)
  
  if(i > 1){
    data_temp <- cross_validation$splits[[i]] %>% analysis()
    
    for(j in 2:i){
      assign(paste0("PIB per Capita",j), data_temp$GDPercapita^j)
      data_temp <- cbind(data_temp, get(paste0("PIB per Capita", j)))
    }
    colnames(data_temp) <- c("Expectativa de vida", "PIB per Capita", paste0("PIB per Capita", 2:i))
    
    fit_temp <- lm(data_temp$`Expectativa de vida`~. , data = data_temp)
    
    Validatiion_temp <- cross_validation$splits[[i]] %>% assessment() 
    
    for(j in 2:i){
      assign(paste0("PIB per Capita", j), Validatiion_temp$GDPercapita^j)
      Validatiion_temp <- cbind(Validatiion_temp, get(paste0("PIB per Capita", j)))
    }
    colnames(Validatiion_temp) <- c("Expectativa de vida", "PIB per Capita", paste0("PIB per Capita", 2:i))
    
    eqm[i] <- mean((Validatiion_temp[,1] - predict(fit_temp, Validatiion_temp))^2)
  }
}
v=which(eqm == min(eqm))
print(v)        

```

3-Explique qual o motivo que faz com que o Erro Quadrático Médio - EQM para avaliar o desempenho de um modelo é ruim quando não adotamos nenhuma estratégia de divisão do conjunto de dados em treinamento e teste.


4-Com suas palavras, explique o dilema de balanço entre víes e variância.

5-Refaça o exercício do polinômio, utilizando a estratégia de data splitting, em que divide-se o conjunto de dados em treinamento e teste. Utilize o conjunto de teste para calcular a estimativa do risco, usando o EQM.

k-folds cross-validation utilizando data splitting com k =50
```{r message=FALSE, warning=FALSE}
dados <- dados_expectativa_renda[,-1]

dados_splitted <- initial_split(dados, prop = 3/4)
train_data <- training(dados_splitted)
test_data <- testing(dados_splitted)

cross_validation <- vfold_cv(train_data, v = 50)

eqm <- NULL

for(i in 1:50){
  data_temp <- cross_validation$splits[[i]] %>% analysis()
  fit_temp <- lm(data_temp$LifeExpectancy~., data_temp)
  
  Validatiion_temp <- cross_validation$splits[[i]] %>% assessment()
  
  eqm[i] <-  apply((Validatiion_temp[,1] - predict(fit_temp, Validatiion_temp))^2, MARGIN = 2, mean)
  
  if(i > 1){
    data_temp <- cross_validation$splits[[i]] %>% analysis()
    
    for(j in 2:i){
      assign(paste0("PIB per Capita",j), data_temp$GDPercapita^j)
      data_temp <- cbind(data_temp, get(paste0("PIB per Capita", j)))
    }
    colnames(data_temp) <- c("Expectativa de vida", "PIB per Capita", paste0("PIB per Capita", 2:i))
    
    fit_temp <- lm(data_temp$`Expectativa de vida`~. , data = data_temp)
    
    Validatiion_temp <- cross_validation$splits[[i]] %>% assessment() 
    
    for(j in 2:i){
      assign(paste0("PIB per Capita", j), Validatiion_temp$GDPercapita^j)
      Validatiion_temp <- cbind(Validatiion_temp, get(paste0("PIB per Capita", j)))
    }
    colnames(Validatiion_temp) <- c("Expectativa de vida", "PIB per Capita", paste0("PIB per Capita", 2:i))
    
    eqm[i] <- mean((Validatiion_temp[,1] - predict(fit_temp, Validatiion_temp))^2)
  }
}

v=which(eqm == min(eqm))
print(v)        
```


6- Ainda considerando o exercício do polinômio, implemente uma estratégia de leave-one-out cross-validation e selecione o melhor modelo minimizando a função de risco.


Leave-one-out cross-validation;
```{r message=FALSE, warning=FALSE}
dados <- dados_expectativa_renda[,-1]

cross_validation <- loo_cv(dados)

eqm <- NULL

for(i in 1:50){
  data_temp <- cross_validation$splits[[i]] %>% analysis()
  fit_temp <- lm(data_temp$LifeExpectancy~., data_temp)
  
  Validatiion_temp <- cross_validation$splits[[i]] %>% assessment()
  
  eqm[i] <-  apply((Validatiion_temp[,1] - predict(fit_temp, Validatiion_temp))^2, MARGIN = 2, mean)
  
  if(i > 1){
    data_temp <- cross_validation$splits[[i]] %>% analysis()
    
    for(j in 2:i){
      assign(paste0("PIB per Capita",j), data_temp$GDPercapita^j)
      data_temp <- cbind(data_temp, get(paste0("PIB per Capita", j)))
    }
    colnames(data_temp) <- c("Expectativa de vida", "PIB per Capita", paste0("PIB per Capita", 2:i))
    
    fit_temp <- lm(data_temp$`Expectativa de vida`~. , data = data_temp)
    
    Validatiion_temp <- cross_validation$splits[[i]] %>% assessment() 
    
    for(j in 2:i){
      assign(paste0("PIB per Capita", j), Validatiion_temp$GDPercapita^j)
      Validatiion_temp <- cbind(Validatiion_temp, get(paste0("PIB per Capita", j)))
    }
    colnames(Validatiion_temp) <- c("Expectativa de vida", "PIB per Capita", paste0("PIB per Capita", 2:i))
    
    eqm[i] <- mean((Validatiion_temp[,1] - predict(fit_temp, Validatiion_temp))^2)
  }
}

v=which(eqm == min(eqm))
print(v)      
```

7- Por fim, considerando o exercício do polinômio, rafaça-o utilizando um procedimento de kk-fold cross-validation. Considere k = 5k=5. Dica: considere utiliza a biblioteca rsample.


k-folds cross-validation utilizando data splitting com k = 5
```{r message=FALSE, warning=FALSE}
dados <- dados_expectativa_renda[,-1]

dados_splitted <- initial_split(dados, prop = 3/4)
train_data <- training(dados_splitted)
test_data <- testing(dados_splitted)

cross_validation <- vfold_cv(train_data, v = 5)

eqm <- NULL

for(i in 1:5){
  data_temp <- cross_validation$splits[[i]] %>% analysis()
  fit_temp <- lm(data_temp$LifeExpectancy~., data_temp)
  
  Validatiion_temp <- cross_validation$splits[[i]] %>% assessment()
  
  eqm[i] <-  apply((Validatiion_temp[,1] - predict(fit_temp, Validatiion_temp))^2, MARGIN = 2, mean)
  
  if(i > 1){
    data_temp <- cross_validation$splits[[i]] %>% analysis()
    
    for(j in 2:i){
      assign(paste0("PIB per Capita",j), data_temp$GDPercapita^j)
      data_temp <- cbind(data_temp, get(paste0("PIB per Capita", j)))
    }
    colnames(data_temp) <- c("Expectativa de vida", "PIB per Capita", paste0("PIB per Capita", 2:i))
    
    fit_temp <- lm(data_temp$`Expectativa de vida`~. , data = data_temp)
    
    Validatiion_temp <- cross_validation$splits[[i]] %>% assessment() 
    
    for(j in 2:i){
      assign(paste0("PIB per Capita", j), Validatiion_temp$GDPercapita^j)
      Validatiion_temp <- cbind(Validatiion_temp, get(paste0("PIB per Capita", j)))
    }
    colnames(Validatiion_temp) <- c("Expectativa de vida", "PIB per Capita", paste0("PIB per Capita", 2:i))
    
    eqm[i] <- mean((Validatiion_temp[,1] - predict(fit_temp, Validatiion_temp))^2)
  }
}

v=which(eqm == min(eqm))
print(v)        
```

 - Vinhos


```{r}

vinhos <- read.csv("E:/Downloads/archive (7)/winequality-red.csv")
skimr::skim(vinhos)
```
```{r}
colnames(vinhos) <- c(paste0("x", 1:11), "y")
#Data split
vinho <- initial_split(vinhos, prop = 3/4)

trainer <- training(vinho)
tester <- testing(vinho)

#Setting Engine
modelo_mmo <- 
  linear_reg(penalty = 0, mixture = 0) %>% 
  set_mode("regression") %>% 
  set_engine("glmnet")

modelo_ridge <- 
  linear_reg(penalty = tune::tune(), mixture = 0) %>% 
  set_mode("regression") %>% 
  set_engine("glmnet")

modelo_lasso <- 
  parsnip::linear_reg(penalty = tune::tune(), mixture = 1) %>% 
  set_mode("regression") %>% 
  parsnip::set_engine("glmnet")

modelo_elastic <- 
  parsnip::linear_reg(penalty = tune::tune(), mixture = tune::tune()) %>% 
  set_mode("regression") %>% 
  parsnip::set_engine("glmnet")


#workflow
all_wf <- 
  workflow_set(
    preproc = list(y ~ . ),
    models = list(mmo = modelo_mmo, ridge = modelo_ridge, lasso = modelo_lasso, elastic = modelo_elastic), 
    cross = TRUE
  )

#cross-validation
set.seed(2023)
cv <- rsample::vfold_cv(trainer, v = 5L)

#metrics
metrica <- yardstick::metric_set(rmse)

#tunning
tunagem <- 
  all_wf %>%  
  workflow_map(
    seed = 2023, 
    verbose = TRUE,
    resamples = cv,
    grid = 50,
    metrics = metrica
  )
```


```{r}
#melhores modelos
modelos_rank <- tunagem %>% rank_results()

melhor_mmo <- 
  tunagem %>% 
  extract_workflow_set_result("formula_mmo") %>% 
  select_best("rmse")

melhor_ridge <- 
  tunagem %>% 
  extract_workflow_set_result("formula_ridge") %>% 
  select_best("rmse")

melhor_lasso <- 
  tunagem %>% 
  extract_workflow_set_result("formula_lasso") %>% 
  select_best("rmse")

melhor_elastic <- 
  tunagem %>% 
  extract_workflow_set_result("formula_elastic") %>% 
  select_best("rmse")

finalizando_mmo <- 
  tunagem %>% 
  extract_workflow("formula_mmo") %>% 
  finalize_workflow(melhor_mmo) %>% 
  last_fit(split = vinho)

finalizando_ridge <- 
  tunagem %>% 
  extract_workflow("formula_ridge") %>% 
  finalize_workflow(melhor_ridge) %>% 
  last_fit(split = vinho)

finalizando_lasso <- 
  tunagem %>% 
  extract_workflow("formula_lasso") %>% 
  finalize_workflow(melhor_lasso) %>% 
  last_fit(split = vinho)

finalizando_elastic <- 
  tunagem %>% 
  extract_workflow("formula_elastic") %>% 
  finalize_workflow(melhor_elastic) %>% 
  last_fit(split = vinho)
```

```{r}
library(knitr)
kable(data.frame(row.names = c("MMO", "Ridge", "Lasso", "Elastic"), 
                        "RMSE" = as.numeric(c((finalizando_mmo  %>%  collect_metrics())[1,3],
                                              (finalizando_ridge %>% collect_metrics())[1,3],
                                              (finalizando_lasso %>% collect_metrics())[1,3],
                                              (finalizando_elastic %>% collect_metrics())[1,3])))
             
             
)
```

```{r}


features <- trainer[,-12] %>% as.matrix()
ytrainer <- trainer[,12] %>% as.matrix()
testfeatures <- tester[,-12] %>% as.matrix()
ytest <- tester[,12] %>% as.matrix()

#MMO

fit <- glmnet(x = features, y = ytrainer, alpha = 0, lambda = 0)
preditos <- predict(fit, newx = testfeatures)
eqm_mmo <- mean((preditos - ytest)^2)


#Ridge
cvridge <- cv.glmnet(x = features, y = ytrainer, alpha = 0, nfolds = 5)
fit2 <- glmnet(x = features, y = ytrainer, alpha = 0)
preditos_ridge <- predict(fit2, s = cvridge$lambda.1se, newx = testfeatures)
eqm_ridge <- mean((preditos_ridge - ytest)^2)

#Lasso
cvlasso <- cv.glmnet(x = features, y = ytrainer, alpha = 1, nfolds = 5)
fit3 <- glmnet(x = features, y = ytrainer, alpha = 1)
preditos_lasso <- predict(fit3, s = cvlasso$lambda.1se, newx = testfeatures)
eqm_lass <- mean((preditos_lasso - ytest)^2)

#Elastic-net
#Precisamos estipular o melhor alpha através de uma validaçao cruzada.
#Utilizando 5-folds.
eqm_elastic <- NULL
alpha_values <- seq(0.01, 0.999, length.out = 500)
for(a in alpha_values){
  cvelastic <- cv.glmnet(x = features, y = ytrainer, alpha = a, nfolds = 5)
  tempfit <- glmnet(x = features, y = ytrainer, alpha = a)
  preditos_elastic <- predict(tempfit, s = cvelastic$lambda.1se, newx = testfeatures)
  eqm_elastic <- c(eqm_elastic, 
                   mean((preditos_elastic - ytest)^2)) 
}
print(min(eqm_elastic))

kable(data.frame(row.names = c("MMO", "Ridge", "Lasso", "Elastic"),
                        "EQM" = c(eqm_mmo, eqm_ridge, eqm_lass, min(eqm_elastic)),
                        "RMSE" = sqrt(c(eqm_mmo, eqm_ridge, eqm_lass, min(eqm_elastic)))
                        )
)
```

 - despesas médicas

```{r}
despesas <- read.csv("insurance.csv")

dados_t <- recipe(charges ~., data = despesas) %>% 
  step_dummy(all_nominal(), -all_outcomes()) %>% 
  prep() %>% juice() 

knitr::kable(dados_t %>% head(10), format = "html")
```

```{r}
df <- initial_split(dados_t, prop = 3/4)

trainer <- training(df)
tester <- testing(df)

#Setting Engine
modelo_mmo <- 
  linear_reg(penalty = 0, mixture = 0) %>% 
  set_mode("regression") %>% 
  set_engine("glmnet")

modelo_ridge <- 
  linear_reg(penalty = tune::tune(), mixture = 0) %>% 
  set_mode("regression") %>% 
  set_engine("glmnet")

modelo_lasso <- 
  parsnip::linear_reg(penalty = tune::tune(), mixture = 1) %>% 
  set_mode("regression") %>% 
  parsnip::set_engine("glmnet")

modelo_elastic <- 
  parsnip::linear_reg(penalty = tune::tune(), mixture = tune::tune()) %>% 
  set_mode("regression") %>% 
  parsnip::set_engine("glmnet")


#workflow
all_wf <- 
  workflow_set(
    preproc = list(charges ~ . ),
    models = list(mmo = modelo_mmo, ridge = modelo_ridge, lasso = modelo_lasso, elastic = modelo_elastic), 
    cross = TRUE
  )

#cross-validation
set.seed(2023)
cv <- rsample::vfold_cv(trainer, v = 5L)

#metrics
metrica <- yardstick::metric_set(rmse)

#tunning
tunagem <- 
  all_wf %>%  
  workflow_map(
    seed = 2023, 
    verbose = TRUE,
    resamples = cv,
    grid = 50,
    metrics = metrica
  )
```
```{r}
modelos_rank <- tunagem %>% rank_results()

melhor_mmo <- 
  tunagem %>% 
  extract_workflow_set_result("formula_mmo") %>% 
  select_best("rmse")

melhor_ridge <- 
  tunagem %>% 
  extract_workflow_set_result("formula_ridge") %>% 
  select_best("rmse")

melhor_lasso <- 
  tunagem %>% 
  extract_workflow_set_result("formula_lasso") %>% 
  select_best("rmse")

melhor_elastic <- 
  tunagem %>% 
  extract_workflow_set_result("formula_elastic") %>% 
  select_best("rmse")

finalizando_mmo <- 
  tunagem %>% 
  extract_workflow("formula_mmo") %>% 
  finalize_workflow(melhor_mmo) %>% 
  last_fit(split = df)

finalizando_ridge <- 
  tunagem %>% 
  extract_workflow("formula_ridge") %>% 
  finalize_workflow(melhor_ridge) %>% 
  last_fit(split = df)

finalizando_lasso <- 
  tunagem %>% 
  extract_workflow("formula_lasso") %>% 
  finalize_workflow(melhor_lasso) %>% 
  last_fit(split = df)

finalizando_elastic <- 
  tunagem %>% 
  extract_workflow("formula_elastic") %>% 
  finalize_workflow(melhor_elastic) %>% 
  last_fit(split = df)


knitr::kable(data.frame(row.names = c("MMO", "Ridge", "Lasso", "Elastic"), 
                        "RMSE" = as.numeric(c((finalizando_mmo  %>%  collect_metrics())[1,3],
                                              (finalizando_ridge %>% collect_metrics())[1,3],
                                              (finalizando_lasso %>% collect_metrics())[1,3],
                                              (finalizando_elastic %>% collect_metrics())[1,3])))
)

```

seleção de modelos
```{r}
data_temp <- data.frame(ychapeu_mmo = (finalizando_mmo %>% collect_predictions())[2],
                        ychapeu_ridge = (finalizando_ridge %>% collect_predictions())[2],
                        ychapeu_lasso = (finalizando_lasso %>% collect_predictions())[2],
                        ychapeu_elastic = (finalizando_elastic %>% collect_predictions())[2],
                        y = (finalizando_elastic %>% collect_predictions())[4]
)

colnames(data_temp) <- c("ychapeu_mmo", "ychapeu_ridge", "ychapeu_lasso", "ychapeu_elastic", "y")
data_temp <- as_tibble(data_temp)


g1 <- ggplot(data_temp, aes(x = ychapeu_mmo, y = y)) +
  geom_point() + geom_line(aes(y = ychapeu_mmo), colour = "#191970", size = 1) +
  labs(title = "Modelo MMO", subtitle = "y_ajustado vs y_real")

g2 <- ggplot(data_temp, aes(x = ychapeu_ridge, y = y)) +
  geom_point() + geom_line(aes(y = ychapeu_ridge), colour = "#4169E1", size = 1) +
  labs(title = "Modelo ridge", subtitle = "y_ajustado vs y_real")

g3 <- ggplot(data_temp, aes(x = ychapeu_lasso, y = y)) +
  geom_point() + geom_line(aes(y = ychapeu_lasso), colour = "orange", size = 1) +
  labs(title = "Modelo lasso", subtitle = "y_ajustado vs y_real")

g4 <- ggplot(data_temp, aes(x = ychapeu_elastic, y = y)) +
  geom_point() + geom_line(aes(y = ychapeu_elastic), colour = "red", size = 1) +
  labs(title = "Modelo elastic", subtitle = "y_ajustado vs y_real")


(g1 + g2) / (g3 + g4)
```

